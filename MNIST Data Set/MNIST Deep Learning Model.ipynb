{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=gzip.open(\"mnist.pkl.gz\",'rb')\n",
    "f.seek(0)\n",
    "training_data,validation_data,test_data=pickle.load(f,encoding='latin1')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       " array([5, 0, 4, ..., 8, 4, 8], dtype=int64))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature data is :\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature data is :\\n{0}\".format(training_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target data is :\n",
      "[5 0 4 ... 8 4 8]\n"
     ]
    }
   ],
   "source": [
    "print(\"Target data is :\\n{0}\".format(training_data[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points are: 50000\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of data points are: {0}\".format(len(training_data[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points in each data point are 784\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of points in each data point are {0}\".format(len(training_data[0][1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we have to do one hot encoding of the target data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The idea is to create 10*m matrix for m length data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "data=np.array([1,2,3,0])\n",
    "n_cols=data.shape[0]# new array columns are equal to actual array length\n",
    "new_array=np.zeros((10,n_cols))\n",
    "index=0\n",
    "for value in data:\n",
    "    new_array[value][index]=1.0\n",
    "    index+=1\n",
    "print(new_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's create function for loading data and one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    f=gzip.open(\"mnist.pkl.gz\",'rb')\n",
    "    training_data,validation_data,test_data=pickle.load(f,encoding='latin1')\n",
    "    f.close()\n",
    "    return training_data,validation_data,test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(data):\n",
    "    n_cols=data.shape[0]# new array columns are equal to actual array length\n",
    "    new_array=np.zeros((10,n_cols))\n",
    "    index=0\n",
    "    for value in data:\n",
    "        new_array[value][index]=1.0\n",
    "        index+=1\n",
    "    return new_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_d,val_d,tst_d=load_data()\n",
    "tr_X=np.array(tr_d[0][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For implementation in Keras, the desired shape is m $\\times$ n, where m is number of training samples and n is number of parts in each datapoint which looks absolutely clear, 50000 data points with each data point having 784 parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 50000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_y=one_hot_encoding(np.array(tr_d[1][:]))\n",
    "tr_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to transpose the tr_y shape to m $\\times$ n format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_y=tr_y.T\n",
    "tr_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_up():\n",
    "    tr_d,val_d,test_d=load_data()\n",
    "    train_set_x=np.array(tr_d[0][:])\n",
    "    train_results=np.array(tr_d[1][:])\n",
    "    train_set_y=one_hot_encoding(train_results).T\n",
    "    test_set_x=np.array(val_d[0][:])\n",
    "    test_results=np.array(val_d[1][:])\n",
    "    test_set_y=one_hot_encoding(test_results).T\n",
    "    return train_set_x,train_set_y,test_set_x,test_set_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x, train_set_y, test_set_x, test_set_y = wrap_up()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set_x shape (50000, 784)\n",
      "train_set_y shape (50000, 10)\n",
      "test_set_x shape (10000, 784)\n",
      "test_set_y shape (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"train_set_x shape {0}\".format(train_set_x.shape))\n",
    "print(\"train_set_y shape {0}\".format(train_set_y.shape))\n",
    "print(\"test_set_x shape {0}\".format(test_set_x.shape))\n",
    "print(\"test_set_y shape {0}\".format(test_set_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAARIUlEQVR4nO3de7BV5X3G8e8jSiFqvBERVDDeq5nxMgy1g1pMlOKlasZLZYxSosXpxGkzk9Z6icVGGZVRYmIdJ8dLRU0xsYh3JY6tIdpRQbxh8MpIOIKgEnugOhrk1z/2InPAvd+9z74ezvt8Zs6cfdZvv3v92JznrLX22mu/igjMbODbqtMNmFl7OOxmmXDYzTLhsJtlwmE3y4TDbpYJhz0Dkp6SdH4Hxv6dpFWS1knapZ7HsOZx2Lcgkt6VdGyn+6iFpG2AmcCEiNguIj4qc59vSlokqUfSUklT299pPhx2a5XhwBDgtXLF4o/BXOBnwA7AXwMzJR3Stg4z47APAJJ2kvSwpA8k/b64vcdmd9tH0vOS/lfSA5J27jX+CEn/I+ljSS9LGl/jev9E0g2SVhRfNxTL9gfeKO72saT/KjN8Z+CrwF1RsgBYAhzU5yfAauKwDwxbAf8OjAZGAZ8C/7bZfc4FvguMBNYDPwWQtDvwCHAVpQD+IzBH0tdqWO9lwBHAocAhwFjghxHxJnBwcZ8dI+Kbmw+MiFXAbGCKpEGS/rzo/+ka/83WRw77ABARH0XEnIj4JCLWAtOBv9jsbndFxOKI+D/gcuBMSYOA7wCPRsSjEbEhIp4AFgIn1LDqs4EfRcTqiPgA+FfgnD60Phv4F+Az4DfAZRGxvA/jrQ8c9gFA0lck/UzSMkk9wHxgxyLMG/UO0TJgG2AYpa3pGcUu/MeSPgaOBEbUsOqRxWP1ftyRNfZ8IPALSnscgyntCVwk6cRaxlvfOewDww+AA4A/i4ivAkcXy9XrPnv2uj0K+APwIaU/AndFxI69vraNiGtqWO8KSn8sej/uihp7/gbwRkTMK/Yo3qB0OHF8jeOtjxz2Lc82kob0+toa2J7ScfrHxQtv08qM+46kgyR9BfgR8J8R8QVwN/BXkv6yOHYeIml8mRf4ypkN/FDS1yQNo7RLfneN/44Xgf2K02+StA9wEvByjeOtjxz2Lc+jlIK98esK4AZgKKUt9bPA42XG3QXcAbxP6ZTY3wMUx8inAJcCH1Da0v8Ttf1uXEXp+P4V4FVgUbGsqoh4h9ILhj8FeoBfA3OA22oZb30nf3iFWR68ZTfLhMNulgmH3SwTDrtZJrZu58ok+dVAsxaLCJVb3tCWXdJESW9IelvSxY08lpm1Vt2n3oq3Yr4JHAd0AwuASRHx28QYb9nNWqwVW/axwNsRsTQiPgfuofTmDDPrhxoJ++5senFFd7FsE5KmSlooaWED6zKzBjXyAl25XYUv7aZHRBfQBd6NN+ukRrbs3Wx6JdUe1H7Fk5m1WSNhX0DpqqWvSxoMnAU82Jy2zKzZ6t6Nj4j1ki4E5gGDgNsjouyHC5pZ57X1qjcfs5u1XkveVGNmWw6H3SwTDrtZJhx2s0w47GaZcNjNMuGwm2XCYTfLhMNulgmH3SwTDrtZJhx2s0w47GaZcNjNMuGwm2XCYTfLhMNulgmH3SwTDrtZJhx2s0w47GaZcNjNMuGwm2XCYTfLhMNulgmH3SwTDrtZJhx2s0w47GaZqHvKZus/Lrjggoq18847Lzl2zJgxyfqyZcuS9aOOOipZ7+7uTtZTzjnnnGT9tdfSM4QvWrSo7nUPRA2FXdK7wFrgC2B9RKR/c8ysY5qxZT8mIj5swuOYWQv5mN0sE42GPYBfSXpB0tRyd5A0VdJCSQsbXJeZNaDR3fhxEbFC0q7AE5Jej4j5ve8QEV1AF4CkaHB9ZlanhrbsEbGi+L4amAuMbUZTZtZ8dYdd0raStt94G5gALG5WY2bWXIqob89a0t6UtuZQOhz4j4iYXmWMd+PL2HfffZP1hx56qO7xW23V2tdg586dm6yffvrpFWsHHHBAcuxzzz2XrF977bXJ+tVXX52sD1QRoXLL6z5mj4ilwCF1d2RmbeVTb2aZcNjNMuGwm2XCYTfLhMNulglf4toG22+/fbJ+yy23JOv7779/sp66jPTmm29Ojn3qqaeS9WeeeSZZHzRoULKeMnz48GS92vO2fPnyutedI2/ZzTLhsJtlwmE3y4TDbpYJh90sEw67WSYcdrNM+Dx7G1x00UXJ+tFHH52s33///cn6lClTKtZ6enqSY4cOHZqst9KoUaMaGv/iiy82qZM8eMtulgmH3SwTDrtZJhx2s0w47GaZcNjNMuGwm2XC59nboNFz2TNmzEjWq51LT9lhhx3qHluL1DXp1aZk/uSTT5L1Rv7dOfKW3SwTDrtZJhx2s0w47GaZcNjNMuGwm2XCYTfLhM+zbwFGjx6drFeb2jjl+OOPT9bXrVuXrF9//fXJ+oQJEyrWjj322OTYBQsWJOv+3Pi+qbpll3S7pNWSFvdatrOkJyS9VXzfqbVtmlmjatmNvwOYuNmyi4EnI2I/4MniZzPrx6qGPSLmA2s2W3wKMKu4PQs4tcl9mVmT1XvMPjwiVgJExEpJu1a6o6SpwNQ612NmTdLyF+giogvoApAUrV6fmZVX76m3VZJGABTfVzevJTNrhXrD/iAwubg9GXigOe2YWatU3Y2XNBsYDwyT1A1MA64BfinpPOB3wBmtbHJL9+mnnzY0vtq57JNOOqli7brrrmto3ffee2+y/v777zc0PuWBB7wNaaaqYY+ISRVK32pyL2bWQn67rFkmHHazTDjsZplw2M0y4bCbZUIR7XtTW67voEt9nDLAPffck6wfd9xxyfqgQYMq1tavX58c+/rrryfrp512WrJ+xhnps65XXXVVxdqcOXOSY6t91PRnn32WrOcqIlRuubfsZplw2M0y4bCbZcJhN8uEw26WCYfdLBMOu1kmfJ59C3D++ecn61OmTKlYO+KII5rdziaksqd0/6i7u7ti7ZhjjkmOfeedd+rqKXc+z26WOYfdLBMOu1kmHHazTDjsZplw2M0y4bCbZcLn2QeAoUOHVqxdffXVybHVrkffbbfdkvVq59nnzZtXsVZtumirj8+zm2XOYTfLhMNulgmH3SwTDrtZJhx2s0w47GaZ8Hn2zHV1dSXr1a6lr3aePfX7dffddyfHnnvuucm6lVf3eXZJt0taLWlxr2VXSHpP0kvF1wnNbNbMmq+W3fg7gIlllv84Ig4tvh5tbltm1mxVwx4R84E1bejFzFqokRfoLpT0SrGbv1OlO0maKmmhpIUNrMvMGlRv2G8G9gEOBVYC11e6Y0R0RcSYiBhT57rMrAnqCntErIqILyJiA3ALMLa5bZlZs9UVdkkjev34bWBxpfuaWf+wdbU7SJoNjAeGSeoGpgHjJR0KBPAucEELe7QGVPts9mrXlFd7H8YjjzySrA8bNqxibdKkScmxy5cvT9Yvu+yyZN02VTXsEVHuf+S2FvRiZi3kt8uaZcJhN8uEw26WCYfdLBMOu1kmqr4ab1u2Aw88MFkfOXJksn7fffcl62effXaynjp1d/rppyfHTp8+PVnfa6+9kvVqveXGW3azTDjsZplw2M0y4bCbZcJhN8uEw26WCYfdLBM+zz7AnXzyycn6hg0bkvVbb701Wf/888/73NNGs2fPTtb33nvvZP3yyy9P1m+88caKtWeffTY5diDylt0sEw67WSYcdrNMOOxmmXDYzTLhsJtlwmE3y4SnbB4Ahg8fXrG2dOnS5NiHHnooWT/rrLPq6qkZql1rP3/+/GS9p6enYu3www+vq6ctQd1TNpvZwOCwm2XCYTfLhMNulgmH3SwTDrtZJhx2s0zUMmXznsCdwG7ABqArIn4iaWfgF8BelKZtPjMift+6Vq2Srbeu/N84ZMiQ5NjRo0c3u52mWbFiRbJe7Vr7adOmVaxVm6r6scceS9a3RLVs2dcDP4iIPwWOAL4n6SDgYuDJiNgPeLL42cz6qaphj4iVEbGouL0WWALsDpwCzCruNgs4tVVNmlnj+nTMLmkv4DDgOWB4RKyE0h8EYNdmN2dmzVPzZ9BJ2g6YA3w/Inqksm+/LTduKjC1vvbMrFlq2rJL2oZS0H8eERtn+lslaURRHwGsLjc2IroiYkxEjGlGw2ZWn6phV2kTfhuwJCJm9io9CEwubk8GHmh+e2bWLLXsxo8DzgFelfRSsexS4Brgl5LOA34HnNGaFq2adevWVay99957ybGHHXZYsj527Nhk/fnnn0/WW6nav23w4MEVax988EGz2+n3qoY9Ip4GKh2gf6u57ZhZq/gddGaZcNjNMuGwm2XCYTfLhMNulgmH3SwT/ijpAa7aZaBTpkxp6PFnzJiRrD/99NMVa6NGjUqO3WWXXZL1Sy65JFn/6KOPKtYOPvjg5Ni1a9cm6/2ZP0raLHMOu1kmHHazTDjsZplw2M0y4bCbZcJhN8uEz7MPcBMnTkzW586dm6ynrgkHqPbxZO38/drc448/XrF24okntrGT9vJ5drPMOexmmXDYzTLhsJtlwmE3y4TDbpYJh90sEz7Pnrnx48cn61deeWWyPm7cuGS9kd+vNWvWJOszZ85M1m+66aaKtZ6enrp62hL4PLtZ5hx2s0w47GaZcNjNMuGwm2XCYTfLhMNulomq59kl7QncCewGbAC6IuInkq4A/hbYONH1pRHxaJXH8nl2sxardJ69lrCPAEZExCJJ2wMvAKcCZwLrIuK6Wptw2M1ar1LYt65h4EpgZXF7raQlwO7Nbc/MWq1Px+yS9gIOA54rFl0o6RVJt0vaqcKYqZIWSlrYUKdm1pCa3xsvaTvg18D0iLhP0nDgQyCAKynt6n+3ymN4N96sxeo+ZgeQtA3wMDAvIr509UGxxX84Ir5R5XEcdrMWq/tCGJU+PvQ2YEnvoBcv3G30bWBxo02aWevU8mr8kcBvgFcpnXoDuBSYBBxKaTf+XeCC4sW81GN5y27WYg3txjeLw27Wer6e3SxzDrtZJhx2s0w47GaZcNjNMuGwm2XCYTfLhMNulgmH3SwTDrtZJhx2s0w47GaZcNjNMuGwm2Wi6gdONtmHwLJePw8rlvVH/bW3/toXuLd6NbO30ZUKbb2e/UsrlxZGxJiONZDQX3vrr32Be6tXu3rzbrxZJhx2s0x0OuxdHV5/Sn/trb/2Be6tXm3praPH7GbWPp3esptZmzjsZpnoSNglTZT0hqS3JV3ciR4qkfSupFclvdTp+emKOfRWS1rca9nOkp6Q9Fbxvewcex3q7QpJ7xXP3UuSTuhQb3tK+m9JSyS9JukfiuUdfe4SfbXleWv7MbukQcCbwHFAN7AAmBQRv21rIxVIehcYExEdfwOGpKOBdcCdG6fWkjQDWBMR1xR/KHeKiH/uJ71dQR+n8W5Rb5WmGf8bOvjcNXP683p0Yss+Fng7IpZGxOfAPcApHeij34uI+cCazRafAswqbs+i9MvSdhV66xciYmVELCpurwU2TjPe0ecu0VdbdCLsuwPLe/3cTf+a7z2AX0l6QdLUTjdTxvCN02wV33ftcD+bqzqNdzttNs14v3nu6pn+vFGdCHu5qWn60/m/cRFxOHA88L1id9VqczOwD6U5AFcC13eymWKa8TnA9yOip5O99Famr7Y8b50IezewZ6+f9wBWdKCPsiJiRfF9NTCX0mFHf7Jq4wy6xffVHe7njyJiVUR8EREbgFvo4HNXTDM+B/h5RNxXLO74c1eur3Y9b50I+wJgP0lflzQYOAt4sAN9fImkbYsXTpC0LTCB/jcV9YPA5OL2ZOCBDvayif4yjXelacbp8HPX8enPI6LtX8AJlF6Rfwe4rBM9VOhrb+Dl4uu1TvcGzKa0W/cHSntE5wG7AE8CbxXfd+5Hvd1FaWrvVygFa0SHejuS0qHhK8BLxdcJnX7uEn215Xnz22XNMuF30JllwmE3y4TDbpYJh90sEw67WSYcdrNMOOxmmfh/QnxkJxqjtqUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# change the index range from 0 to 49,999 to visualize different digits \n",
    "index=49999\n",
    "k=train_set_x[index,:]\n",
    "k=k.reshape((28,28))\n",
    "plt.title('Label of {label}'.format(label=training_data[1][index]))\n",
    "plt.imshow(k,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Models are defined in sequence of layers \n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "nn_model = Sequential()\n",
    "\n",
    "2. Number of components in input vector , here 28*28=784\n",
    "3. Number of hidden layers as well as we want the connection to be Dense, every neuron in one layer is connected to every other neuron in adjacent layer. here we are adding 1 hidden layer with 35 neurons\n",
    "4. Activation function 'relu'\n",
    "\n",
    "from keras.layers import Dense\n",
    "\n",
    "nn_model.add(Dense(35, input_dim=784, activation='relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ersha\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ersha\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ersha\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nn_model = Sequential()\n",
    "nn_model.add(Dense(35, input_dim=784, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from keras.layers import Dropout, BatchNormalization, Activation\n",
    "5. If you want to use Dropout in particular layer\n",
    "\n",
    "nn_model.add(Dropout(0.3)) # 0.3 is percentage of neurons that dropout\n",
    "6. We can also add hidden layers, adding 1 hidden layer with 21 neurons\n",
    "\n",
    "nn_model.add(Dense(21, activation='relu'))\n",
    "7. We can also include regularization using the command\n",
    "\n",
    "from keras import regularizers\n",
    "\n",
    "nn_model.add(Dense(21, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "\n",
    "8. The last output layer is the softmax layer with 10 classes defined\n",
    "nn_model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout,BatchNormalization,Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ersha\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ersha\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "nn_model.add(Dropout(0.3))\n",
    "nn_model.add(Dense(21, activation = 'relu'))\n",
    "nn_model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>We have to compile the model on training dataset so we have to use different parameters, such as loss function , optimizer and evaluation metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ersha\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ersha\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nn_model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Now we can fit the model, on our training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ersha\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/12\n",
      "50000/50000 [==============================] - 20s 395us/step - loss: 0.4866 - acc: 0.8509\n",
      "Epoch 2/12\n",
      "50000/50000 [==============================] - 26s 519us/step - loss: 0.3089 - acc: 0.9055\n",
      "Epoch 3/12\n",
      "50000/50000 [==============================] - 25s 507us/step - loss: 0.2762 - acc: 0.9146\n",
      "Epoch 4/12\n",
      "50000/50000 [==============================] - 26s 521us/step - loss: 0.2556 - acc: 0.9202\n",
      "Epoch 5/12\n",
      "50000/50000 [==============================] - 39s 783us/step - loss: 0.2472 - acc: 0.9228\n",
      "Epoch 6/12\n",
      "50000/50000 [==============================] - 52s 1ms/step - loss: 0.2328 - acc: 0.9271\n",
      "Epoch 7/12\n",
      "50000/50000 [==============================] - 24s 489us/step - loss: 0.2269 - acc: 0.9285\n",
      "Epoch 8/12\n",
      "50000/50000 [==============================] - 28s 569us/step - loss: 0.2184 - acc: 0.9313\n",
      "Epoch 9/12\n",
      "50000/50000 [==============================] - 22s 436us/step - loss: 0.2132 - acc: 0.9336\n",
      "Epoch 10/12\n",
      "50000/50000 [==============================] - 29s 590us/step - loss: 0.2053 - acc: 0.9361\n",
      "Epoch 11/12\n",
      "50000/50000 [==============================] - 27s 549us/step - loss: 0.2056 - acc: 0.9349\n",
      "Epoch 12/12\n",
      "11664/50000 [=====>........................] - ETA: 28s - loss: 0.2000 - acc: 0.9363"
     ]
    }
   ],
   "source": [
    "nn_model.fit(train_set_x,train_set_y,epochs=12,batch_size=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_train=nn_model.evaluate(train_set_x,train_set_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{0} :{1}%\".format(nn_model.metrics_names[1],score_train[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Evaluate on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score_test=nn_model.evaluate(test_set_x,test_set_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{0} :{1}%\".format(nn_model.metrics_names[1],score_test[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Model has achieved 96.44% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Check predictions and look for wrong predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=nn_model.predict(test_set_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax([0.2,0.3,0.4,0.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.2+0.3+0.4+0.1=1\n",
    "0.4 has maximum probability hence the the index 2 is its value similarly each data point is to be evaluated along its column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=np.argmax(prediction,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels=np.argmax(test_set_y,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=188\n",
    "k=test_set_x[index,:]\n",
    "k=k.reshape((28,28))\n",
    "plt.title(\"Label is {label}\".format(label=(test_labels[index],prediction[index])))\n",
    "plt.imshow(k,cmap='grey')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can change values to see which vsalues have been misclassified"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
